{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "saved-interface",
   "metadata": {},
   "source": [
    "# 4장 신경망 학습\n",
    "\n",
    "- 학습: 훈련 데이터로부터 가중치 매개변수의 최적값을 자동으로 획득하는 것.\n",
    "- 학습의 목표: 손실 함수의 결과값을 가장 작게 만드는 가중치 매개변수를 찾는 것. \n",
    "- 경사법: 함수의 기울기를 활용하여 손실함수의 값을 작게 만드는 기법\n",
    "## 4.1 데이터에서 학습한다!\n",
    "\n",
    "### 4.1.1 데이터 주도 학습 \n",
    "- 사람: 사람의 경험과 직관을 단서로 시행착오를 거듭해 결과를 얻음\n",
    "- 기계학습: 핵심은 데이터. 사람이 이미지를 벡터로 변환할 때 사용하는 특징(SVM, KNN 등)을 설계한 후, 그 특징의 패턴을 기계로 학습함. 문제에 적합한 특징을 설계하지 않으면 좋은 결과를 얻을 수 없다. \n",
    "- 신경망: 이미지에 포함된 중요한 특징도 기계가 스스로 학습하고, 주어진 문제의 패턴을 발견한다. 즉 모든 문제를 주어진 데이터 그대로 입력 데이터로 활용해 'end-to-end'로 학습한다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "biological-birthday",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "![](https://images.velog.io/images/guide333/post/1a2ff5a8-b2af-4237-ab25-9b3a0b0f097a/Screenshot%20from%202021-03-28%2017-52-09.png)\n",
    "\n",
    "### 4.1.2 훈련 데이터와 시험 데이터\n",
    "훈련 데이터에 포함되지 않은 새로운 데이터로도 문제를 올바르게 풀어내는 범용 능력을 제대로 평가하기 위해 훈련 데이터와 시험 데이터를 분리한다. 범용 능력을 획득하는 것이 기계학습의 최종 목표이다. \n",
    "\n",
    "- 훈련 데이터(training data): 최적의 매개변수 찾기\n",
    "- 시험 데이터(test data): 훈련한 모델의 범용 능력 평가\n",
    "- 오버피팅(overfitting): 한 데이터셋에만 지나치게 최적화된 상태. 오버피팅을 피해야 함. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intended-identification",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 4.2 손실 함수\n",
    "- 손실함수: 신경망 성능의 '나쁨'을 나타내는 지표. 현재의 신경망이 훈련 데이터를 얼마나 잘 처리하지 못했느냐를 나타낸다. 손실함수를 기준으로 최적의 매개변수 값을 탐색한다. 일반적으로 평균 제곱 오차와 교차 엔트로피 오차를 사용한다. \n",
    "\n",
    "### 4.2.1 평균 제곱 오차(Mean Squared Error, MSE)\n",
    "- 평균 제곱 오차의 수식: $E=\\frac{1}{2} \\sum_k (y_k-t_k)^2$          \n",
    "($y_k$: 신경망의 출력(신경망이 추정한 값), $t_k$: 정답 레이블, $k$: 데이터의 차원수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "coordinate-taxation",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T09:16:59.381855Z",
     "start_time": "2021-03-28T09:16:59.379387Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# '2'일 확률이 가장 높다고 추정(0.6)\n",
    "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]  # 확률\n",
    "# 정답\n",
    "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]  # 정답: 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "filled-probability",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "신경망의 출력 y는 소프트맥스의 함수의 출력이다. 소프트맥스 함수의 출력은 확률로 해석할 수 있다. 위의 그림에서 이미지가 0일 확률은 0.1, 1일 확률은 0.05로 해석된다. 정답 레이블인 t에서 정답을 의미하는 위치의 원소는 1, 그 외에는 0으로 표기(원-핫 인코딩)하므로 위의 그림에 따르면 정답이 '2'임을 알 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "greatest-tooth",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T09:17:53.017262Z",
     "start_time": "2021-03-28T09:17:53.008124Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def mean_squared_error(y, t): \n",
    "    return 0.5 * np.sum((y-t)**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "resident-drill",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T09:18:38.842583Z",
     "start_time": "2021-03-28T09:18:38.813994Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09750000000000003"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(np.array(y), np.array(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "forty-democracy",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T09:20:21.379405Z",
     "start_time": "2021-03-28T09:20:21.373082Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.59875"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# '7'일 확률이 가장 높다고 추정(0.6)\n",
    "y = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.05]\n",
    "mean_squared_error(np.array(y), np.array(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wound-surname",
   "metadata": {},
   "source": [
    "평군 제곱 오차를 기준으로는 첫 번째 추정 결과(오차가 더 작으므로)가 정답에 더 가까울 것으로 판단된다. \n",
    "\n",
    "### 4.2.2 교차 엔트로피 오차\n",
    "- 교차 엔트로피 오차의 수식: $E=-\\sum_k t_klogy_k$\n",
    "\n",
    "($y_k$: 신경망의 출력(신경망이 추정한 값), $t_k$: 정답 레이블, $k$: 데이터의 차원수)\n",
    "\n",
    "위의 식은 실질적으로 정답일 때의 추정($t_k$가 1일 때의 $y_k$)의 자연로그를 계산하는 식이다. 예를 들어 정답 레이블이 '2'가 정답이고 이 때의 신경망 출력이 0.6이라면 교차 엔트로피 오차는 $-log0.6=0.51$이다. 같은 조건에서 신경망의 출력이 0.1이라면 $-log0.1=2.30$이다. 즉 교차 엔트로피 오차는 정답일 때의 출력이 전체값을 정한다.\n",
    "\n",
    "\n",
    "![](https://images.velog.io/images/guide333/post/43fb1336-3f47-4112-80ac-8001f3132865/Screenshot%20from%202021-03-30%2000-38-15.png)\n",
    "\n",
    "자연로그의 그래프에 의하면 정답에  해당하는 출력이 커질수록 0에 가까워지다가 출력이 1일 때 0이 된다. 정답일 때의 출력이 작아질수록 오차는 커진다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "split-provision",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T12:08:08.310225Z",
     "start_time": "2021-03-28T12:08:08.307929Z"
    }
   },
   "outputs": [],
   "source": [
    "def cross_entropy_error(y, t):            # y, t: 넘파이 배열\n",
    "    delta = 1e-7\n",
    "    return -np.sum(t * np.log(y + delta))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spanish-introduction",
   "metadata": {},
   "source": [
    "delta: log 함수에 0을 넣으면 마이너스 무한대인 -inf가 되어 계산을 할 수 없으므로 아주 작은 값을 더해 -Inf가 나오지 않도록 한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "empirical-inside",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T12:11:35.818927Z",
     "start_time": "2021-03-28T12:11:35.814992Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.510825457099338"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# '2'일 확률이 가장 높다고 추정(0.6)\n",
    "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
    "# 정답 2\n",
    "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "cross_entropy_error(np.array(y), np.array(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "senior-football",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T12:11:47.855077Z",
     "start_time": "2021-03-28T12:11:47.851316Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.302584092994546"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# '7'일 확률이 가장 높다고 추정(0.6)\n",
    "y = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.05]\n",
    "\n",
    "cross_entropy_error(np.array(y), np.array(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vanilla-bacon",
   "metadata": {},
   "source": [
    "결과(오차값)가 더 작은 첫 번째 추정이 정답일 가능성이 높다고 판단하였다. (평균 제곱 오차의 판단과 일치)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baking-array",
   "metadata": {},
   "source": [
    "### 4.2.3 미니배치 학습\n",
    "데이터가 N개일 때의 교차 엔트로피 함수: $E=-\\frac {1}{N} \\sum_n \\sum_n t_{nk}log_{nk}$\n",
    "\n",
    "$t_{nk}$: n번째 데이터의 k차원 째의 값\n",
    "\n",
    "데이터 하나에 대한 손실함수를 N개의 데이터로 확장한 식이다. N으로 나눔으로써 '평균 손실 함수'를 구한다. 평균을 구하면 훈련 데이터의 개수와 상관없이 언제나 통일된 지표를 얻을 수 있다. \n",
    "\n",
    "- 미니배치 학습       \n",
    "훈련 데이터가 많을 때, 데이터의 일부를 선택하여 전체의 '근사치'로 이용한다. 이 데이터의 일부를 '미니배치'라고 하며, 데이터의 일부를 선택하여 학습하는 것을 '미니배치 학습'이라고 한다. \n",
    "\n",
    "훈련 데이터에서 무작위로 몇 장을 뽑으려면 ```np.random.choice()```함수를 사용하면 된다. 이 함수가 출력한 배열을 미니배치로 뽑아낼 데이터의 인덱스로 사용하면 된다.\n",
    "\n",
    "손실함수도 미니배치로 계산한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "subtle-holocaust",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T12:52:19.325353Z",
     "start_time": "2021-03-28T12:52:19.106174Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "#sys.path.append(\"./tensorflow_datasets\") # 이때, dataset 폴더는 실행하는 py 파일의 경로와 일치해야 한다.\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from tensorflow.keras import datasets\n",
    "mnist = datasets.mnist\n",
    "\n",
    "(train_x, train_t),(test_x, test_t) = mnist.load_data()\n",
    "\n",
    "print(train_x.shape)\n",
    "print(train_t.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loose-religion",
   "metadata": {},
   "source": [
    "- 훈련 데이터에서 무작위로 10장 빼내기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "wicked-junction",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T12:52:21.221456Z",
     "start_time": "2021-03-28T12:52:21.218264Z"
    }
   },
   "outputs": [],
   "source": [
    "train_size = train_x.shape[0]\n",
    "batch_size = 10\n",
    "batch_mask = np.random.choice(train_size, batch_size)\n",
    "x_batch = train_x[batch_mask]\n",
    "t_batch = train_t[batch_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "large-stereo",
   "metadata": {},
   "source": [
    "60000 미만의 수 중 무작위로 10개 골라낸다. 이 함수가 출력한 배열을 미니배치로 뽑아낼 데이터의 인덱스로 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "historical-going",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T12:52:22.600552Z",
     "start_time": "2021-03-28T12:52:22.597400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3490, 2178, 5554, 2609, 2794,  378, 5103, 1784, 5099,  191])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(60000,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cosmetic-defensive",
   "metadata": {},
   "source": [
    "### 4.2.4 (배치용) 교차 엔트로피 오차 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "hindu-possibility",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T12:52:24.560918Z",
     "start_time": "2021-03-28T12:52:24.558342Z"
    }
   },
   "outputs": [],
   "source": [
    "# 정답이 원-핫 인코딩일 경우 교차 엔트로피 오차 구현\n",
    "\n",
    "def cross_entropy_error(y, t):\n",
    "    if y.dim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "        \n",
    "        batch_size = y.shape[0]\n",
    "        return -np.sum(t * np.log(y)) / batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overall-massage",
   "metadata": {},
   "source": [
    "y: 신경망의 출력, t: 정답 레이블     \n",
    "- 코드 설명     \n",
    "1. y가 1차원, 즉 데이터 하나당 교차 엔트로피 오차를 구하는 경우는 reshape 함수로 데이터의 형상을 바꾼다. \n",
    "2. 배치의 크기로 나눠 정규화하고 이미지 1장당 평균의 교차 엔트로피 오차를 계산한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "tracked-demographic",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T12:53:49.070865Z",
     "start_time": "2021-03-28T12:53:49.067748Z"
    }
   },
   "outputs": [],
   "source": [
    "# 정답 레이블이 원-핫 인코딩이 아니라 숫자 레이블로 주어졌을 때 교차 엔트로피 오차 구현\n",
    "\n",
    "def cross_entropy_error(y, t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "        \n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(np.log(y[np.arange(batch_size), t])) / batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "veterinary-milton",
   "metadata": {},
   "source": [
    "원-핫 인코딩일 때 t가 0인 원소는 교차 엔트로피 오차도 0이므로 그 계산은 무시한다. 즉 정답에 해당하는 신경망의 출력만으로 교차 엔트로피 오차를 계산할 수 있다. \n",
    "\n",
    "- np.log(y[np.arange(batch_size), t]) 설명     \n",
    "np.arange(batch_size): 0부터 batch_size-1까지 배열 생성\n",
    "y[np.arange(batch_size), t]: 각 데이터의 정답 레이블에 해당하는 신경망의 출력 추출. [y[0,2], y[1,7], y[2,0], y[3,9], y[4,4]]인 넘파이 배열 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "existing-copyright",
   "metadata": {},
   "source": [
    "### 4.2.5 왜 손실함수를 설정하는가?\n",
    "신경망 학습에서 최적의 매개변수(가중치와 편향)을 탐색할 때 손실함수의 값을 작게하는 매개변수 값을 찾는다. \n",
    "\n",
    "- 신경망 학습의 방법      \n",
    "1. 매개변수의 손실함수의 미분(기울기)를 계산한다.\n",
    "2. 미분값을 단서로 매개변수 값을 갱신한다.\n",
    "  - 미분값이 음수: 가중치의 매개변수를 양의 방향으로 변화 -> 손실함수의 값을 줄임   \n",
    "  - 미분값이 양수: 가중치의 매개변수를 음의 방향으로 변화 -> 손실함수의 값 줄임 \n",
    "  - 미분값이 0: 손실함수의 값이 변하지 않으므로 가중치 매개변수의 갱신은 멈춘다.\n",
    "\n",
    "- 정확도를 지표로 삼으면 안 되는 이유     \n",
    "미분값이 대부분의 장소에서 0이 되어 매개변수를 갱신할 수 없기 때문이다. 정확도는 매개변수의 작은 변화에는 거의 반응을 보이지 않고 반응이 있더라도 그 값이 불연속적으로 갑자기 변한다. \n",
    "\n",
    "그러나 손실함수는 매개변수의 값이 조금 변하면 손실 함수의 값도 연속적으로 변하기 때문에 손실함수로 지표를 삼는다. \n",
    "\n",
    "- 참고: 계단함수를 활성화 함수로 사용하지 않는 이유\n",
    "정확도를 지표로 삼지 않는 이유는 '계단함수'를 활성화 함수로 사용하지 않는 이유와도 일맥상통한다. 계단 함수의 미분은 대부분의 장소(0 제외)에서 0이므로 계단 함수를 이용하면 손실 함수를 지표로 삼는 것이 아무 의미가 없다. 매개변수의 작은 변화를 계단 함수가 제거하기 때문에 손실함수의 값에 아무 변화가 없을 것이다. \n",
    "\n",
    "![](https://images.velog.io/images/guide333/post/dd009a59-c05f-4f42-8715-3e06dff7cccb/Screenshot%20from%202021-03-30%2000-53-20.png)\n",
    "\n",
    "- 계단함수: 한순간의 변화\n",
    "- 시그모이드 함수: 미분(접선)은 출력과 곡선의 기울기도 연속적으로 변한다. 즉 어느 장소에서도 미분값이 0이 되지 않는다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interested-raleigh",
   "metadata": {},
   "source": [
    "## 4.3 수치 미분\n",
    "### 4.3.1 미분\n",
    "- 미분: '한순간'의 변화량, 수식은 아래와 같다. \n",
    "\n",
    "$$ \\frac {df(x)}{dx} = lim_{h \\to 0} \\frac {f(x+h)-f(x)}{h}$$\n",
    "\n",
    "- 좌변: f(x)의 x에 대한 미분(x에 대한 f(x)의 변화량)을 나타내는 변화량   \n",
    "x의 작은 변화가 함수 f(x)를 얼마나 변화시키느냐의 의미 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banner-chancellor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 나쁜 구현의 예\n",
    "def numerical_diff(f, x):\n",
    "    h = 10e-50\n",
    "    return (f(x + h) - f(x)) / h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ongoing-principle",
   "metadata": {},
   "source": [
    "- 수치미분의 문제점 2개 존재\n",
    "\n",
    "> 수치 미분: 해석적 미분 방식으로는 풀 수 없는 문제가 있을 때 수치적 접근을 통해 근사 값을 찾는 방식. 아주 작은 차분으로 미분함으로써, 미분 공식과 근사적으로 가까운 결과를 낸다. (참고: https://chacha95.github.io/2018-11-01-numerical/)\n",
    "\n",
    "1. 반올림 오차    \n",
    "```h = 10e-50```로 설정했을 때, float32형(32비트 부동소수점으로 나타내면 0.0이 된다.\n",
    "2. 함수의 차분(임의의 두 점에서의 함수 값의 차이)   \n",
    "'진정한 미분'은 x 위치의 함수의 기울기(접선)이지만 위의 식에서의 미분은 (x+h)와 x 사이의 기울기이다. 즉 진정한 미분(진정한 접선)과 위의 식의 구현은 일치하지 않는다. 이 차이는 h를 무한히 0으로 좁히는 것이 불가능해서 생기는 한계이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "peaceful-subsection",
   "metadata": {},
   "source": [
    "![](https://images.velog.io/images/guide333/post/678e921f-a349-4c8a-9eef-64d12cd0cf97/Screenshot%20from%202021-03-28%2021-43-30.png)\n",
    "\n",
    "위 그림과 같이 수치 미분에는 오차가 포함되어 있으므로 오차를 줄이기 위해 중심 차분을 사용한다. 즉 $(x+h)$와 $(x-h)$일 때의 함수 f의 차분을 계산하는 방법을 사용한다. \n",
    "\n",
    "$$ \\frac {df(x)}{dx} = lim_{h \\to 0} \\frac {f(x+h)-f(x-h)}{2h}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "painful-double",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T13:05:53.637796Z",
     "start_time": "2021-03-28T13:05:53.635490Z"
    }
   },
   "outputs": [],
   "source": [
    "def numerical_diff(f, x):\n",
    "    h = 1e-4  # 0.0001, 너무 작은 값을 넣으면 0.0으로 컴퓨터는 인식한다.\n",
    "    return (f(x+h)-f(x-h)) /(2*h)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "meaningful-craps",
   "metadata": {},
   "source": [
    "### 4.3.2 수치 미분의 예\n",
    "$$y=0.01x^2 + 0.1x$$\n",
    "\n",
    "위의 식을 계산한 미분 값은 x에 대한 f(x)의 변화량, 즉 기울기이다. \n",
    "- 해석적 해법: $\\frac{df(x)}{dx} = 0.02x + 1$   \n",
    "- 진정한 미분값    \n",
    "x=5: $\\frac{df(x)}{dx} =  0.2$, x=10: $\\frac{df(x)}{dx} = 0.3$ \n",
    "\n",
    "아래의 값과 비교하면 오차가 매우 작다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "enormous-cocktail",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-29T16:12:09.609555Z",
     "start_time": "2021-03-29T16:12:09.484905Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def function_1(x):\n",
    "    return 0.01*x**2 + 0.1*x\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.arange(0.0, 20.0, 0.1) # 간격 0.1\n",
    "y = function_1(x)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"f(x)\")\n",
    "plt.plot(x, y)\n",
    "plt.title(\"y=0.01x^2 + 0.1x의 그래프\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "atlantic-drill",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T13:05:55.057752Z",
     "start_time": "2021-03-28T13:05:55.055053Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1999999999990898"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_diff(function_1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "toxic-world",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T13:05:56.289948Z",
     "start_time": "2021-03-28T13:05:56.287138Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2999999999986347"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_diff(function_1, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "treated-qualification",
   "metadata": {},
   "source": [
    "- 수치 미분값을 기울기로 하는 직선    \n",
    "\n",
    "![](https://images.velog.io/images/guide333/post/eff74320-7ae2-4cb9-858b-c3391cee530c/Screenshot%20from%202021-03-30%2001-17-05.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mysterious-sharp",
   "metadata": {},
   "source": [
    "### 4.3.3 편미분\n",
    "$$f(x_0, x_1) = x_0^2 + x_1^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "stuck-limitation",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T13:09:11.198930Z",
     "start_time": "2021-03-28T13:09:11.196744Z"
    }
   },
   "outputs": [],
   "source": [
    "def function_2(x):          # X: 넘파이 배열\n",
    "    return x[0]**2 + x[1]**2    # return np.sum(x**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thrown-notebook",
   "metadata": {},
   "source": [
    "![](https://images.velog.io/images/guide333/post/863f0bd5-f06a-4f3e-a092-f5b094e64f7e/Screenshot%20from%202021-03-28%2022-09-40.png)\n",
    "\n",
    "- 편미분: 변수가 여럿인 함수에 대한 미분. $\\frac {\\partial f}{\\partial x_0}$\n",
    "\n",
    "- 편미분 구하기 \n",
    "$x_0= 3, x_1=4$일 때 $x_0$에 대한 편미분 $\\frac {\\partial f}{\\partial x_0}$ 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "funny-contract",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T13:16:24.136046Z",
     "start_time": "2021-03-28T13:16:24.133090Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.00000000000378"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def function_tmp1(x0):\n",
    "    return x0*x0 + 4.0**2.0\n",
    "\n",
    "numerical_diff(function_tmp1, 3.0)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hawaiian-sauce",
   "metadata": {},
   "source": [
    "$x_0= 3, x_1=4$일 때 $x_0$에 대한 편미분 $\\frac {\\partial f}{\\partial x_1}$ 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "accessory-orientation",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T13:17:20.354000Z",
     "start_time": "2021-03-28T13:17:20.350638Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.999999999999119"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def function_tmp2(x1):\n",
    "    return 3.0**2.0 + x1*x1\n",
    "\n",
    "numerical_diff(function_tmp2, 4.0)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upper-century",
   "metadata": {},
   "source": [
    "편미분은 특정 장소의 기울기를 구하지만 여러 변수 중 목표 변수 하나에 초점을 맞추고 다른 변수의 값을 고정한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indirect-section",
   "metadata": {},
   "source": [
    "## 4.4 기울기\n",
    "기울기: 모든 변수의 편미분을 벡터로 정의한 것. $(\\frac {\\partial f}{\\partial x_0}, \\frac {\\partial f}{\\partial x_1})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "average-williams",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T13:26:58.983381Z",
     "start_time": "2021-03-28T13:26:58.979974Z"
    }
   },
   "outputs": [],
   "source": [
    "def numerical_gradient(f, x):\n",
    "    h = 1e-4\n",
    "    grad = np.zeros_like(x)  # x와 형상이 같고 원소가 모두 0인 배열 생성\n",
    "    \n",
    "    for idx in range(x.size):\n",
    "        tmp_val = x[idx]\n",
    "        \n",
    "        # f(x+h) 계산, 이해가 안 됨.... \n",
    "        x[idx] = tmp_val + h\n",
    "        fxh1 = f(x)\n",
    "        \n",
    "        # f(x-h) 계산\n",
    "        x[idx] = tmp_val - h\n",
    "        fxh2 = f(x)\n",
    "        \n",
    "        grad[idx] = (fxh1 - fxh2) / (2*h)\n",
    "        x[idx] = tmp_val  # 값 복원\n",
    "        \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "romantic-remark",
   "metadata": {},
   "source": [
    "- 세 점에서의 기울기 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "clean-public",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T13:27:00.348052Z",
     "start_time": "2021-03-28T13:27:00.344732Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6., 8.])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_gradient(function_2, np.array([3.0, 4.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "modular-bosnia",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T13:27:12.274926Z",
     "start_time": "2021-03-28T13:27:12.269122Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 4.])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_gradient(function_2, np.array([0.0, 2.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "accompanied-parks",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T13:27:30.163534Z",
     "start_time": "2021-03-28T13:27:30.160293Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6., 0.])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_gradient(function_2, np.array([3.0, 0.0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elder-coalition",
   "metadata": {},
   "source": [
    "- 아래의 그림은 기울길의 결과에 마이터스를 붙인 벡터 \n",
    "\n",
    "![](https://images.velog.io/images/guide333/post/c6b414c5-e2c3-4813-b4b5-0d54a887eb5d/Screenshot%20from%202021-03-28%2022-28-33.png)\n",
    "\n",
    "기울기 그림은 방향을 가진 벡터(화살표)로 그려진다. 기울기는 함수의 '가장 낮은 장소(최솟값)'을 가리키고, '가장 낮은 곳'에서 멀어질수록 화살표의 크기가 커진다. \n",
    "\n",
    "__기울기가 가리키는 쪽은 _각 장소_ 에서 함수의 출력값을 가장 줄이는 방향__ 이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minus-evidence",
   "metadata": {},
   "source": [
    "### 4.4.1 경사법(경사 하강법)\n",
    "신경망은 손실함수가 최솟값이 될 때의 가중치와 편향을 학습할 때 찾아야 한다.\n",
    "- 경사법: 기울기를 잘 이용해 함수의 최솟값(또는 가능한 한 작은값)을 찾는 것   \n",
    "\n",
    "- 주의: 복잡한 함수에서는 기울기가 가리키는 방향에 최솟값이 없는 경우가 대부분이다.\n",
    "\n",
    ">기울기가 0인 곳\n",
    ">1. 극솟값: 국소적인 최솟값\n",
    ">2. 최솟값\n",
    ">3. 안장점(saddle point): 어느 방향에서는 극댓값이고 다른 방향에서는 극솟값인 점    \n",
    ">\n",
    ">복잡하고 찌그러진 모양의 함수의 경우, 평평한 곳으로 파고들면서 학습이 진행되지 않는 정체기(고원)에 빠질 수 있다.\n",
    "\n",
    "- 경사법: 현 위치에서 기울어진 방향으로 일정 거리만큼 이동해 기울기를 구하고, 또 그 기울어진 방향으로 이동하는 것을 반복하면서 함수의 값을 점차 줄이는 방법이다. \n",
    "\n",
    ">경사법에는 경사하강법(최솟값 찾기)과 경사상승법(최댓값 찾기)가 있으나 신경망에서는 경사하강법을 주로 사용한다.\n",
    "\n",
    "- 경사법의 수식    \n",
    "$x_0 = x_0 - \\eta \\frac {\\partial f}{\\partial x_0}$\n",
    "$x_1 = x_1 - \\eta \\frac {\\partial f}{\\partial x_1}$\n",
    "\n",
    "$\\eta$는 __학습률(lenaring rate)__ 이고 한 번의 학습에서 매개변수 값을 얼마나 갱신하느냐를 정한다. \n",
    "\n",
    "위의 식은 1회 갱신하는 양이고 이 단계를 반복하면서 서서히 함수의 값을 줄인다. \n",
    "\n",
    "학습률 값은 0.01이나 0.001 등 미리 특정 값으로 정해햐 하는데, 이 값이 너무 크거나 작으면 '좋은 장소'를 찾아갈 수 없다. 신경망 학습에서는 보통 이 학습률 값을 변경하면서 제대로 학습하고 있는지를 확인하면서 진행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "noble-china",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T13:53:45.273075Z",
     "start_time": "2021-03-28T13:53:45.270571Z"
    }
   },
   "outputs": [],
   "source": [
    "# 경사하강법\n",
    "def gradient_descent(f, init_x, lr=0.01, step_num=100):\n",
    "    x = init_x  # 초기값\n",
    "    \n",
    "    for i in range(step_num):\n",
    "        grad = numerical_gradient(f, x)  # 함수의 기울기\n",
    "        x -= lr * grad\n",
    "        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alleged-albert",
   "metadata": {},
   "source": [
    "f: 최적화하려는 함수, init_x: 초깃값, lr: 학습률, step_num: 경사법에 따른 반복횟수\n",
    "\n",
    "- 경사법으로 $f(x_0, x_1) = x_0^2 + x_1^2$의 최솟값 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "adjusted-tooth",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T14:01:29.397206Z",
     "start_time": "2021-03-28T14:01:29.388453Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.11110793e-10,  8.14814391e-10])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def function_2(x):\n",
    "    return x[0]**2 + x[1]**2\n",
    "\n",
    "init_x = np.array([-3.0, 4.0])\n",
    "gradient_descent(function_2, init_x=init_x, lr=0.1, step_num=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smart-moore",
   "metadata": {},
   "source": [
    "초기값 (-3.0, 4.0)으로 설정한 후, 경사법을 사용해 최솟값 탐색을 시작한다. 최종결과는 (0,0)에 가깝고, 진정한 최솟값은 (0,0)이므로 경사법으로 거의 정확한 결과를 얻었다. \n",
    "\n",
    "경사법을 사용한 갱신과정은 아래의 그림과 같이 된다. 값이 가장 낮은 장소인 원점에 점차 가까워지고 있다. \n",
    "\n",
    "![](https://images.velog.io/images/guide333/post/0f94c940-56c6-4e75-bc02-280cabf787f3/Screenshot%20from%202021-03-28%2023-03-05.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "through-venture",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T14:06:33.397188Z",
     "start_time": "2021-03-28T14:06:33.392138Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.58983747e+13, -1.29524862e+12])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습률이 너무 큰 예\n",
    "\n",
    "init_x = np.array([-3.0, 4.0])\n",
    "gradient_descent(function_2, init_x=init_x, lr=10.0, step_num=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "turned-scoop",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T14:07:02.610675Z",
     "start_time": "2021-03-28T14:07:02.600869Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.99999994,  3.99999992])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습률이 너무 작은 예\n",
    "\n",
    "init_x = np.array([-3.0, 4.0])\n",
    "gradient_descent(function_2, init_x=init_x, lr=1e-10, step_num=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advance-links",
   "metadata": {},
   "source": [
    "학습률이 너무 크면 큰 값으로 발산하고, 너무 작으면 거의 갱신되지 않고 학습이 끝난다. 따라서 학습률을 적절히 설정하는 것이 중요하다. \n",
    "\n",
    "> - 하이퍼파리미터: 사람이 직접 설정해야 하는 매개변수, 예: 학습률. \n",
    "> - 매개변수: 훈련데이터와 학습 알고리즘에 의해 '자동'으로 획득되는 매개변수, 예: 가중치, 편향\n",
    "\n",
    "### 4.4.2 신경망에서의 기울기\n",
    "신경망 학습에서도 기울기를 구해야 한다. 여기서의 기울기는 가중치 매개변수에 관한 손실 함수의 기울기이다. \n",
    "\n",
    "- 형상이 2x3, 가중치가 W, 손실함수가 L인 신경망에서 경사는 $\\frac {\\partial L}{\\partial W}$이다. \n",
    "\n",
    "$$ W = \\begin{pmatrix} w_{11} & w_{21} & w_{31} \\\\ w_{12} & w_{22} & w_{32} \\end {pmatrix}$$\n",
    "\n",
    "$$ \\frac {\\partial L}{\\partial W} = \\begin{pmatrix} \\frac {\\partial L}{\\partial w_{11}}  & \\frac {\\partial L}{\\partial w_{21}}  & \\frac {\\partial L}{\\partial w_{31}}  \\\\  \\frac {\\partial L}{\\partial w_{12}} & \\frac {\\partial L}{\\partial w_{22}}  & \\frac {\\partial L}{\\partial w_{32}}  \\end {pmatrix}$$\n",
    "\n",
    "$\\frac {\\partial L}{\\partial W}$의 각 원소는 각각의 원소에 관한 손실함수 L의 편미분이다. 중요한 점은 $\\frac {\\partial L}{\\partial W}$의 형상이 W와 같다는 것이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "valued-quest",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T14:23:23.024383Z",
     "start_time": "2021-03-28T14:23:23.020438Z"
    }
   },
   "outputs": [],
   "source": [
    "# 신경망\n",
    "# x: 입력 데이터, t: 정답레이블\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "\n",
    "class simpleNet:\n",
    "    def __init__(self):\n",
    "        self.W = np.random.randn(2, 3) # 정규 분포로 초기화\n",
    "        \n",
    "    def predict(self, x):       # 예측\n",
    "        return np.dot(x, self.W)\n",
    "    \n",
    "    def loss(self, x, t):       # 손실함수의 값 구하기\n",
    "        z = self.predict(x)\n",
    "        y = softmax(z)\n",
    "        loss = cross_entropy_error(r, t)\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "canadian-mills",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T14:23:48.159345Z",
     "start_time": "2021-03-28T14:23:48.153596Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.48393713  1.40504059 -0.41674296]\n",
      " [-1.13322214 -1.4546533  -1.24281261]]\n"
     ]
    }
   ],
   "source": [
    "net = simpleNet()\n",
    "print(net.W)       # 가중치 매개변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "loaded-military",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T14:24:19.423136Z",
     "start_time": "2021-03-28T14:24:19.418925Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.72953765 -0.46616362 -1.36857713]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([0.6, 0.9])\n",
    "p = net.predict(x)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "smart-lemon",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T14:24:34.607061Z",
     "start_time": "2021-03-28T14:24:34.603795Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "broken-heater",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-29T16:31:55.104765Z",
     "start_time": "2021-03-29T16:31:55.102733Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "t = np.array([0,0,1]) # 정답 레이블\n",
    "net.loss(x, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mechanical-hospital",
   "metadata": {},
   "source": [
    "- 기울기 구하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "identified-commission",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-29T16:32:01.642728Z",
     "start_time": "2021-03-29T16:32:01.640802Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def f(W):\n",
    "    return net.loss(x, t)\n",
    "\n",
    "dW = numerical_gradient(f, net.W)\n",
    "print(dW)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quiet-people",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 4.5 학습 알고리즘 구현하기\n",
    "- 신경망 학습의 절차\n",
    "0. 전제: 신경망에는 적응 가능한 가중치와 편향이 있고, 가중치와 편향을 훈련 데이터에 적응하도록 조정하는 과정을 '학습'이라 한다.\n",
    "1. 미니배치    \n",
    "훈련 데이터의 일부를 무작위로 가져온다. (미니배치의 손실 함수 값을 줄이는 것이 목표)\n",
    "2. 기울기 산출   \n",
    "각 가중치의 매개변수의 기울기를 구한다. 기울기는 손실 함수의 값을 가장 작게 하는 방향을 제시한다. \n",
    "3. 매개변수 갱신    \n",
    "가중치 매개변수를 기울기 방향으로 조금씩 갱신한다.\n",
    "4. 반복   \n",
    "1-3단계 반복"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
